
//! Autogenerated weights for `pallet_edge_connect`
//!
//! THIS FILE WAS AUTO-GENERATED USING THE SUBSTRATE BENCHMARK CLI VERSION 39.0.0
//! DATE: 2024-08-05, STEPS: `50`, REPEAT: `20`, LOW RANGE: `[]`, HIGH RANGE: `[]`
//! WORST CASE MAP SIZE: `1000000`
//! HOSTNAME: `zcalz-MS-7B84`, CPU: `AMD Ryzen 5 3600 6-Core Processor`
//! WASM-EXECUTION: `Compiled`, CHAIN: `Some("dev")`, DB CACHE: `1024`

// Executed Command:
// ./target/release/cyborg-node
// benchmark
// pallet
// --chain=dev
// --pallet=pallet_edge_connect
// --extrinsic=*
// --steps=50
// --repeat=20
// --template
// .maintain/frame-weight-template.hbs
// --output
// pallets/edge-connect/src/weights.rs

#![cfg_attr(rustfmt, rustfmt_skip)]
#![allow(unused_parens)]
#![allow(unused_imports)]
#![allow(missing_docs)]

use frame_support::{traits::Get, weights::{Weight, constants::RocksDbWeight}};
use core::marker::PhantomData;

/// Weight functions needed for `pallet_edge_connect`.
pub trait WeightInfo {
	fn register_worker() -> Weight;
	fn remove_worker() -> Weight;
}

/// Weights for `pallet_edge_connect` using the Substrate node and recommended hardware.
pub struct SubstrateWeight<T>(PhantomData<T>);
impl<T: frame_system::Config> WeightInfo for SubstrateWeight<T> {
	/// Storage: `WorkerClusters::AccountWorkers` (r:1 w:1)
	/// Proof: `WorkerClusters::AccountWorkers` (`max_values`: None, `max_size`: Some(48), added: 2523, mode: `MaxEncodedLen`)
	/// Storage: `WorkerClusters::WorkerClusters` (r:0 w:1)
	/// Proof: `WorkerClusters::WorkerClusters` (`max_values`: None, `max_size`: Some(233), added: 2708, mode: `MaxEncodedLen`)
	fn register_worker() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `42`
		//  Estimated: `3513`
		// Minimum execution time: 17_360_000 picoseconds.
		Weight::from_parts(17_670_000, 3513)
			.saturating_add(T::DbWeight::get().reads(1_u64))
			.saturating_add(T::DbWeight::get().writes(2_u64))
	}
	/// Storage: `WorkerClusters::WorkerClusters` (r:1 w:1)
	/// Proof: `WorkerClusters::WorkerClusters` (`max_values`: None, `max_size`: Some(233), added: 2708, mode: `MaxEncodedLen`)
	fn remove_worker() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `206`
		//  Estimated: `3698`
		// Minimum execution time: 13_850_000 picoseconds.
		Weight::from_parts(14_130_000, 3698)
			.saturating_add(T::DbWeight::get().reads(1_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
}

// For backwards compatibility and tests.
impl WeightInfo for () {
	/// Storage: `WorkerClusters::AccountWorkers` (r:1 w:1)
	/// Proof: `WorkerClusters::AccountWorkers` (`max_values`: None, `max_size`: Some(48), added: 2523, mode: `MaxEncodedLen`)
	/// Storage: `WorkerClusters::WorkerClusters` (r:0 w:1)
	/// Proof: `WorkerClusters::WorkerClusters` (`max_values`: None, `max_size`: Some(233), added: 2708, mode: `MaxEncodedLen`)
	fn register_worker() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `42`
		//  Estimated: `3513`
		// Minimum execution time: 17_360_000 picoseconds.
		Weight::from_parts(17_670_000, 3513)
			.saturating_add(RocksDbWeight::get().reads(1_u64))
			.saturating_add(RocksDbWeight::get().writes(2_u64))
	}
	/// Storage: `WorkerClusters::WorkerClusters` (r:1 w:1)
	/// Proof: `WorkerClusters::WorkerClusters` (`max_values`: None, `max_size`: Some(233), added: 2708, mode: `MaxEncodedLen`)
	fn remove_worker() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `206`
		//  Estimated: `3698`
		// Minimum execution time: 13_850_000 picoseconds.
		Weight::from_parts(14_130_000, 3698)
			.saturating_add(RocksDbWeight::get().reads(1_u64))
			.saturating_add(RocksDbWeight::get().writes(1_u64))
	}
}
